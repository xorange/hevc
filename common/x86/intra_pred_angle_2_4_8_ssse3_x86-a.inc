

%define			SIZE_OF_ANGLE_AP		4


%macro CALC_FILTER_VALUE 0
	PSUBW XMMR2, XMMR5
	PSRAW XMMR2, 1
	PADDW XMMR2, XMMR3
	PMAXSW XMMR2, XMMR6
	PMINSW XMMR2, XMMR7
%endmacro

%macro PREPARE_PARAMETER 0
%if 1 == SIZE_OF_PIXEL
	MOV r0, 1
	MOV ecx, r5m
	SHL r0, cl
	DEC r0
	MOVD XMMR7, r0
	PSHUFB XMMR7, [pshuffw_zero]
	PXOR XMMR6, XMMR6
	MOV ref_main, ref_main_parameter
	MOV dst, dst_parameter
	MOV ref_side, ref_side_parameter
	MOV r0, [ref_side-1]
	AND r0, 0FFH
	MOVD XMMR5, r0
	PSHUFB XMMR5, [pshuffw_zero]
	MOVDQA XMMR4, [ref_side]
	MOV r0, [ref_main]
	AND r0, 0FFH
	MOVD XMMR3, r0
	PSHUFB XMMR3, [pshuffw_zero]
%else
	MOV r0, 1
	MOV ecx, r5m
	SHL r0, cl
	DEC r0
	MOVD XMMR7, r0
	PSHUFB XMMR7, [pshuffw_zero]
	PXOR XMMR6, XMMR6
	MOV ref_main, ref_main_parameter
	MOV dst, dst_parameter
	MOV ref_side, ref_side_parameter
	MOV r0, [ref_side-SIZE_OF_PIXEL]
	AND r0, 0FFFFH
	MOVD XMMR5, r0
	PSHUFB XMMR5, [pshuffw_zero]
	MOV r0, [ref_main]
	AND r0, 0FFFFH
	MOVD XMMR3, r0
	PSHUFB XMMR3, [pshuffw_zero]
%endif
%endmacro

%macro STORE_V 3
%if 1 == SIZE_OF_PIXEL
	MOV ecx, 8
	MOV I, 2
%%STORE_V_I:
	MOVD eax, %3
	MOV J, 4
%%STORE_V_J:
	MOV [%1], al
	ADD_ADDRESS %1, %2
	SHR eax, cl
	DEC J
	JNZ %%STORE_V_J
	PSRLDQ %3, 4
	DEC I
	JNZ %%STORE_V_I
%else
	MOV ecx, 16
	MOV I, 4
%%STORE_V_I:
	MOVD eax, %3
	MOV J, 2
%%STORE_V_J:
	MOV [%1], ax
	ADD_ADDRESS %1, %2
	SHR eax, cl
	DEC J
	JNZ %%STORE_V_J
	PSRLDQ %3, 4
	DEC I
	JNZ %%STORE_V_I
%endif
%endmacro


%macro COPY_ONE_PIXEL_FROM_REF_MAIN		2
%if 1 == SIZE_OF_PIXEL
	MOV al, %2
	MOV %1, al
%else
	MOV ax, %2
	MOV %1, ax
%endif
%endmacro

%macro		COPY_M_PIXEL		3
	%define			ref_main_src						r3
	%define			ref_side							r3
	%define			inv_angle_sum						r2
	MOV ref_main_src, ref_main_parameter
	COPY_ONE_PIXEL_FROM_REF_MAIN [curr_ref_main+SIZE_OF_PIXEL], [ref_main_src-SIZE_OF_PIXEL]
	MOV	I, 0
%%COPY_M_PIXEL_I_1:
	MOVDQA XMMR0, [ref_main_src+I]
	MOVDQA [curr_ref_main+I+2*SIZE_OF_PIXEL], XMMR0
	ADD I, 16
	CMP I, (SIZE_OF_PIXEL*%1)
	JL %%COPY_M_PIXEL_I_1
	MOV I, %2
	IMUL I, %1
	SAR I, 5
	NEG I
	DEC I
	JZ %%COPY_M_PIXEL_EXIT
	MOV ref_side, ref_side_parameter
	MOV inv_angle_sum, 128
%%COPY_M_PIXEL_I_2
	ADD inv_angle_sum, %3
	MOV r0, inv_angle_sum
	SHR r0, 8
	COPY_ONE_PIXEL_FROM_REF_MAIN [curr_ref_main], [ref_side+r0*SIZE_OF_PIXEL-SIZE_OF_PIXEL]
	SUB curr_ref_main, SIZE_OF_PIXEL
	DEC I
	JNZ %%COPY_M_PIXEL_I_2
	%undef			ref_main_src
	%undef			ref_side
	%undef			inv_angle_sum
%%COPY_M_PIXEL_EXIT:
%endmacro

%macro INIT_REF_MAIN_M_MEMORY_CONTENT		3
	%define			curr_ref_main						r4
	SUB r6, (16+%1*2)*SIZE_OF_PIXEL
	MOV curr_ref_main, r6
%if %1 > 8
	ADD curr_ref_main, (14 + %1)* SIZE_OF_PIXEL
%else
	ADD curr_ref_main, 14 * SIZE_OF_PIXEL
%endif
	COPY_M_PIXEL %1, %2, %3
	MOV r0, r6
%if %1 > 8
	ADD r0, (16+%1)*SIZE_OF_PIXEL
%else
	ADD r0, 16*SIZE_OF_PIXEL
%endif
	MOV ref_main, r0
	%undef			curr_ref_main
%endmacro

%macro COPY_INVERSE_MEMORY 3
	%define	ref_side											r4
	MOV ref_main, %1
	MOV ref_side, %2
	MOV I, 0

%%COPY_INVERSE_MEMORY_I:
	SUB ref_main, 16
	MOVDQA XMMR0, [ref_side]
	PSHUFB XMMR0, [pshuffb_reverse]
	MOVDQA [ref_main], XMMR0
	ADD ref_side, 16
	ADD I, 16
	CMP I, %3*SIZE_OF_PIXEL
	JL %%COPY_INVERSE_MEMORY_I
	%undef ref_side
%endmacro

%macro STORE_VECTOR 1
	%define				STORE_VECTOR_R					%1
	MOVDQA [dst], STORE_VECTOR_R
	ADD_ADDRESS dst, i_dst_stride_parameter
%endmacro

%macro LOAD_FROM_REF_MAIN 2-4
%if 4 == %0
	MOV r0, [angle_ap+I*SIZE_OF_ANGLE_AP+(%4*64+(%3))*SIZE_OF_ANGLE_AP]
%if 2 == SIZE_OF_PIXEL
	ADD r0, r0
%endif
	ADD r0, ref_main
	LDDQU %1, [r0+J]
	LDDQU %2, [r0+J+SIZE_OF_PIXEL]
%elif 3 == %0
	MOV r0, [angle_ap+I*SIZE_OF_ANGLE_AP+(%3*64+(%2))*SIZE_OF_ANGLE_AP]
%if 2 == SIZE_OF_PIXEL
	ADD r0, r0
%endif
	ADD r0, ref_main
	LDDQU %1, [r0+J]
%else
	MOV r0, ref_main
	LDDQU XMMR0, [r0+J+(%2)]
	MOVDQA %1, XMMR0
%endif
%endmacro

%macro PREPARE_XMMR1_XMMR2 1
%if 1 == SIZE_OF_PIXEL
	ADD v_delta_pos, %1
	MOV r0, v_delta_pos
	AND r0, 31
	IMUL r0, 16
	MOVDQA XMMR2, [zero_to_32_1+r0]
%else
	ADD v_delta_pos, %1
	MOV r0, v_delta_pos
	AND r0, 31
	IMUL r0, 16
	MOVDQA XMMR1, [zero_to_32+r0]
	MOVDQA XMMR2, [zero_to_32+512]
	PSUBW XMMR2, XMMR1
%endif
%endmacro

%macro CALC_VALUE 0
%if 1 == SIZE_OF_PIXEL
	MOVDQA XMMR4, XMMR0
	PUNPCKLBW XMMR0, XMMR7
	PUNPCKHBW XMMR4, XMMR7
	PMADDUBSW XMMR0, XMMR2
	PMADDUBSW XMMR4, XMMR2
	PADDW XMMR0, [eight_16]
	PADDW XMMR4, [eight_16]
	PSRLW XMMR0, 5
	PSRLW XMMR4, 5
	PACKUSWB XMMR0, XMMR4
%else
	PMULLW XMMR0, XMMR2
	PMULLW XMMR7, XMMR1
	PADDW XMMR0, XMMR7
	PADDW XMMR0, [eight_16]
	PSRLW XMMR0, 5
%endif
%endmacro

%macro GET_REF_MAIN_ADDRESS_TO_R0 1
	MOV r0, [angle_ap+I*SIZE_OF_ANGLE_AP+%1*64*SIZE_OF_ANGLE_AP]
%if 2 == SIZE_OF_PIXEL
	ADD r0, r0
%endif
	ADD r0, ref_main
%endmacro

%macro PREDANG_CALCROW_VER_ONE_UNIT 0
	LDDQU XMMR0, [r0+ J]
	LDDQU XMMR7, [r0+ J+SIZE_OF_PIXEL]
	CALC_VALUE
	MOVDQA [dst+J], XMMR0
%endmacro

%macro PREDANG_CALCROW_VER 3
	PREPARE_XMMR1_XMMR2 %1
	GET_REF_MAIN_ADDRESS_TO_R0 %2
	MOV J, 0
%%PREDANG_CALCROW_VER_LABEL
	PREDANG_CALCROW_VER_ONE_UNIT
	ADD J, 16
	CMP J, %3 * SIZE_OF_PIXEL
	JL %%PREDANG_CALCROW_VER_LABEL
	ADD_ADDRESS dst, i_dst_stride_parameter
%endmacro

%macro COPY_ONE_UNIT 0
	LDDQU XMMR0, [r0+J]
	MOVDQA [dst+J], XMMR0
%endmacro

%macro COPY_ONE_LINE 1
	MOV J, 0
%%COPY_ONE_LINE_LABEL
	COPY_ONE_UNIT
	ADD J, 16
	CMP J, %1 * SIZE_OF_PIXEL
	JL %%COPY_ONE_LINE_LABEL
%endmacro

%if 1 == SIZE_OF_PIXEL

%macro PREDANG_CALCROW_HOR 3
	%define			PREDANG_CALCROW_HOR_START							%1
	%define			PREDANG_CALCROW_HOR_INTRA_ANGLE						%2
	%define			PREDANG_CALCROW_HOR_EIGHT_SUB_LOOK_ID				%3
	PREPARE_XMMR1_XMMR2 %2
	LOAD_FROM_REF_MAIN XMMR0, XMMR7, PREDANG_CALCROW_HOR_START, PREDANG_CALCROW_HOR_EIGHT_SUB_LOOK_ID
	CALC_VALUE
	MOV r0, 16
	IMUL r0, I
	MOVDQA [r0+r6], XMMR0
	%undef			PREDANG_CALCROW_HOR_START
	%undef			PREDANG_CALCROW_HOR_INTRA_ANGLE
	%undef			PREDANG_CALCROW_HOR_EIGHT_SUB_LOOK_ID
%endmacro

%macro PREDANG_CALCROW_HOR_MODE2 3
	PREPARE_XMMR1_XMMR2 %3
	MOVDQA XMMR0, %1
	MOVDQA XMMR7, %2
	CALC_VALUE
	MOV r0, 16
	IMUL r0, I
	MOVDQA [r0+r6], XMMR0
%endmacro

%macro PREDANG_CALCROW_VER_MODE2 3
	PREPARE_XMMR1_XMMR2 %3
	MOVDQA XMMR0, %1
	MOVDQA XMMR7, %2
	CALC_VALUE
	STORE_VECTOR XMMR0
%endmacro

%macro MB8 8
	%define				MB8_R0					%1
	%define				MB8_R1					%2
	%define				MB8_R2					%3
	%define				MB8_R3					%4
	%define				MB8_R4					%5
	%define				MB8_R5					%6
	%define				MB8_R6					%7
	%define				MB8_R7					%8
	MOVDQA XMMR0, MB8_R0
	MOVDQA XMMR1, XMMR0
	PUNPCKLBW XMMR0, MB8_R1
	PUNPCKHBW XMMR1, MB8_R1
	MOVDQA XMMR2, MB8_R2
	MOVDQA XMMR3, XMMR2
	PUNPCKLBW XMMR2, MB8_R3
	PUNPCKHBW XMMR3, MB8_R3
	MOVDQA XMMR4, MB8_R4
	MOVDQA XMMR5, XMMR4
	PUNPCKLBW XMMR4, MB8_R5
	PUNPCKHBW XMMR5, MB8_R5
	PUNPCK 0, 2, 6, WD
	PUNPCK 1, 3, 6, WD
	MOVDQA MB8_R1, XMMR1
	MOVDQA XMMR6, MB8_R6
	MOVDQA XMMR7, XMMR6
	PUNPCKLBW XMMR6, MB8_R7
	PUNPCKHBW XMMR7, MB8_R7
	PUNPCK 4, 6, 1, WD
	PUNPCK 5, 7, 1, WD
	PUNPCK 0, 4, 1, DQ
	MOVDQA MB8_R0, XMMR0
	MOVDQA MB8_R4, XMMR4
	MOVDQA XMMR0, MB8_R1
	MOVDQA XMMR4, XMMR0
	PUNPCKLDQ XMMR0, XMMR5
	PUNPCKHDQ XMMR4, XMMR5
	MOVDQA MB8_R1, XMMR0
	MOVDQA MB8_R5, XMMR4
	PUNPCK 2, 6, 0, DQ
	MOVDQA MB8_R2, XMMR2
	MOVDQA MB8_R6, XMMR6
	PUNPCK 3, 7, 0, DQ
	MOVDQA MB8_R3, XMMR3
	MOVDQA MB8_R7, XMMR7
	%undef				MB8_R0
	%undef				MB8_R1
	%undef				MB8_R2
	%undef				MB8_R3
	%undef				MB8_R4
	%undef				MB8_R5
	%undef				MB8_R6
	%undef				MB8_R7
%endmacro

%macro BLND2_2 2
	%define				BLND2_2_R1					%1
	%define				BLND2_2_R2					%2
	MOVDQA XMMR1, BLND2_2_R1
	MOVDQA XMMR2, BLND2_2_R1
	PUNPCKLQDQ XMMR1, BLND2_2_R2
	PUNPCKHQDQ XMMR2, BLND2_2_R2
	MOVDQA [dst], XMMR1
	ADD_ADDRESS dst, i_dst_stride_parameter
	MOVDQA [dst], XMMR2
	ADD_ADDRESS dst, i_dst_stride_parameter
	%undef				BLND2_2_R1
	%undef				BLND2_2_R2
%endmacro

%macro BLND_16 0
	BLND2_2 R1, R9
	BLND2_2 R5, R13
	BLND2_2 R3, R11
	BLND2_2 R7, R15
	BLND2_2 R2, R10
	BLND2_2 R6, R14
	BLND2_2 R4, R12
	BLND2_2 R8, R16
%endmacro

%macro PREPARE_DST_ADDRESS 1
	%define			PREPARE_DST_ADDRESS_START		%1
	MOV dst, J
	IMUL dst, i_dst_stride_parameter
	ADD dst, PREPARE_DST_ADDRESS_START*SIZE_OF_PIXEL
	ADD dst, dst_parameter
	%undef PREPARE_DST_ADDRESS_START
%endmacro

%macro CALC_FIRST_BLND_ROWS 3
	%define		CALC_FIRST_BLND_ROWS_START								%1
	%define		CALC_FIRST_BLND_ROWS_INTRA_ANGLE						%2
	%define		CALC_FIRST_BLND_ROWS_EIGHT_SUB_LOOK_ID					%3
	PREPARE_DST_ADDRESS	%1
	MOV I, 0
%%CALC_FIRST_BLND_ROWSLABEL:
	PREDANG_CALCROW_HOR %1, %2, %3
	INC I
	CMP I, 16
	JL %%CALC_FIRST_BLND_ROWSLABEL
	MB8 R1,  R2,  R3,  R4,  R5,  R6,  R7,  R8
	MB8 R9,  R10, R11, R12, R13, R14, R15, R16
	BLND_16
	%undef		CALC_FIRST_BLND_ROWS_START
	%undef		CALC_FIRST_BLND_ROWS_INTRA_ANGLE
	%undef		CALC_FIRST_BLND_ROWS_EIGHT_SUB_LOOK_ID
%endmacro CALC_FIRST_BLND_ROWS

%macro CALC_SECOND_BLND_ROWS 3
	%define		CALC_SECOND_BLND_ROWS_START								%1
	%define		CALC_SECOND_BLND_ROWS_INTRA_ANGLE						%2
	%define		CALC_SECOND_BLND_ROWS_EIGHT_SUB_LOOK_ID					%3
	PREPARE_DST_ADDRESS	CALC_SECOND_BLND_ROWS_START
	MOV I, 0
%%CALC_SECOND_BLND_ROWSLABEL:
	PREDANG_CALCROW_HOR %1, %2, %3
	INC I
	CMP I, 15
	JL %%CALC_SECOND_BLND_ROWSLABEL
	ADD v_delta_pos, CALC_SECOND_BLND_ROWS_INTRA_ANGLE
	LOAD_FROM_REF_MAIN XMMR0, CALC_SECOND_BLND_ROWS_START, CALC_SECOND_BLND_ROWS_EIGHT_SUB_LOOK_ID
	MOVDQA R16, XMMR0
	MB8 R1,  R2,  R3,  R4,  R5,  R6,  R7,  R8
	MB8 R9,  R10, R11, R12, R13, R14, R15, R16
	BLND_16
	%undef		CALC_SECOND_BLND_ROWS_START
	%undef		CALC_SECOND_BLND_ROWS_INTRA_ANGLE
	%undef		CALC_SECOND_BLND_ROWS_EIGHT_SUB_LOOK_ID
%endmacro CALC_SECOND_BLND_ROWS

%macro CALC_BLND_ROWS_MODE2 5
	PREPARE_DST_ADDRESS	%5
	MOV I, 0
%%CALC_BLND_ROWS_MODE2
	PREDANG_CALCROW_HOR_MODE2 %1, %2, %4
	INC I
	CMP I, 15
	JL %%CALC_BLND_ROWS_MODE2
	ADD v_delta_pos, %4
	MOVDQA XMMR0, %3
	MOVDQA R16, XMMR0
	MB8 R1,  R2,  R3,  R4,  R5,  R6,  R7,  R8
	MB8 R9,  R10, R11, R12, R13, R14, R15, R16
	BLND_16
%endmacro

%macro CALC_BLND_ROWS_MODE2_VER 4
	MOV I, 0
%%CALC_BLND_ROWS_MODE2_VER_LABEL:
	PREDANG_CALCROW_VER_MODE2 %1, %2, %4
	INC I
	CMP I, 15
	JL %%CALC_BLND_ROWS_MODE2_VER_LABEL
	ADD v_delta_pos, %4
	MOVDQA XMMR0, %3
	STORE_VECTOR XMMR0
%endmacro
%else

%macro PREDANG_CALCROW_HOR 3
	%define			PREDANG_CALCROW_HOR_START							%1
	%define			PREDANG_CALCROW_HOR_INTRA_ANGLE						%2
	%define			PREDANG_CALCROW_HOR_EIGHT_SUB_LOOK_ID				%3
	PREPARE_XMMR1_XMMR2 PREDANG_CALCROW_HOR_INTRA_ANGLE
	LOAD_FROM_REF_MAIN XMMR0, XMMR7, PREDANG_CALCROW_HOR_START, PREDANG_CALCROW_HOR_EIGHT_SUB_LOOK_ID
	CALC_VALUE
	MOV r0, 16
	IMUL r0, I
	MOVDQA [r0+r6], XMMR0
	%undef			PREDANG_CALCROW_HOR_START
	%undef			PREDANG_CALCROW_HOR_INTRA_ANGLE
	%undef			PREDANG_CALCROW_HOR_EIGHT_SUB_LOOK_ID
%endmacro

%macro PREDANG_CALCROW_HOR_MODE2 3
	PREPARE_XMMR1_XMMR2 %3
	MOVDQA XMMR0, %1
	MOVDQA XMMR7, %2
	CALC_VALUE
	MOV r0, 16
	IMUL r0, I
	MOVDQA [r0+r6], XMMR0
%endmacro

%macro PREDANG_CALCROW_VER_MODE2 3
	PREPARE_XMMR1_XMMR2 %3
	MOVDQA XMMR0, %1
	MOVDQA XMMR7, %2
	CALC_VALUE
	STORE_VECTOR XMMR0
%endmacro

%macro MB8 8
	%define				MB8_R0					%1
	%define				MB8_R1					%2
	%define				MB8_R2					%3
	%define				MB8_R3					%4
	%define				MB8_R4					%5
	%define				MB8_R5					%6
	%define				MB8_R6					%7
	%define				MB8_R7					%8
	MOVDQA XMMR0, MB8_R0
	MOVDQA XMMR1, XMMR0
	PUNPCKLWD XMMR0, MB8_R1
	PUNPCKHWD XMMR1, MB8_R1
	MOVDQA XMMR2, MB8_R2
	MOVDQA XMMR3, XMMR2
	PUNPCKLWD XMMR2, MB8_R3
	PUNPCKHWD XMMR3, MB8_R3
	MOVDQA XMMR4, MB8_R4
	MOVDQA XMMR5, XMMR4
	PUNPCKLWD XMMR4, MB8_R5
	PUNPCKHWD XMMR5, MB8_R5
	PUNPCK 0, 2, 6, DQ
	PUNPCK 1, 3, 6, DQ
	MOVDQA MB8_R1, XMMR1
	MOVDQA XMMR6, MB8_R6
	MOVDQA XMMR7, XMMR6
	PUNPCKLWD XMMR6, MB8_R7
	PUNPCKHWD XMMR7, MB8_R7
	PUNPCK 4, 6, 1, DQ
	PUNPCK 5, 7, 1, DQ
	PUNPCK 0, 4, 1, QDQ
	STORE_VECTOR XMMR0
	STORE_VECTOR XMMR4
	PUNPCK 2, 6, 1, QDQ
	STORE_VECTOR XMMR2
	STORE_VECTOR XMMR6
	MOVDQA XMMR0, MB8_R1
	MOVDQA XMMR4, XMMR0
	PUNPCKLQDQ XMMR0, XMMR5
	PUNPCKHQDQ XMMR4, XMMR5
	STORE_VECTOR XMMR0
	STORE_VECTOR XMMR4

	PUNPCK 3, 7, 1, QDQ
	STORE_VECTOR XMMR3
	STORE_VECTOR XMMR7
	%undef				MB8_R0
	%undef				MB8_R1
	%undef				MB8_R2
	%undef				MB8_R3
	%undef				MB8_R4
	%undef				MB8_R5
	%undef				MB8_R6
	%undef				MB8_R7
%endmacro

%macro PREPARE_DST_ADDRESS 1
	%define			PREPARE_DST_ADDRESS_START		%1
	MOV dst, J
	IMUL dst, i_dst_stride_parameter
	ADD dst, PREPARE_DST_ADDRESS_START*SIZE_OF_PIXEL
	ADD dst, dst_parameter
	%undef			PREPARE_DST_ADDRESS_START
%endmacro

%macro CALC_FIRST_BLND_ROWS 3
	%define		CALC_FIRST_BLND_ROWS_START								%1
	%define		CALC_FIRST_BLND_ROWS_INTRA_ANGLE						%2
	%define		CALC_FIRST_BLND_ROWS_EIGHT_SUB_LOOK_ID					%3
	PREPARE_DST_ADDRESS CALC_FIRST_BLND_ROWS_START
	MOV I, 0
%%CALC_FIRST_BLND_ROWS
	PREDANG_CALCROW_HOR CALC_FIRST_BLND_ROWS_START, CALC_FIRST_BLND_ROWS_INTRA_ANGLE, CALC_FIRST_BLND_ROWS_EIGHT_SUB_LOOK_ID
	INC I
	CMP I, 8
	JL %%CALC_FIRST_BLND_ROWS
	MB8 R1,  R2,  R3,  R4,  R5,  R6,  R7,  R8
	%undef		CALC_FIRST_BLND_ROWS_START
	%undef		CALC_FIRST_BLND_ROWS_INTRA_ANGLE
	%undef		CALC_FIRST_BLND_ROWS_EIGHT_SUB_LOOK_ID
%endmacro CALC_FIRST_BLND_ROWS

%macro CALC_SECOND_BLND_ROWS 3
	%define		CALC_SECOND_BLND_ROWS_START								%1
	%define		CALC_SECOND_BLND_ROWS_INTRA_ANGLE						%2
	%define		CALC_SECOND_BLND_ROWS_EIGHT_SUB_LOOK_ID					%3
	PREPARE_DST_ADDRESS CALC_SECOND_BLND_ROWS_START
	MOV I, 0
%%CALC_SECOND_BLND_ROWS
	PREDANG_CALCROW_HOR CALC_SECOND_BLND_ROWS_START, CALC_SECOND_BLND_ROWS_INTRA_ANGLE, CALC_SECOND_BLND_ROWS_EIGHT_SUB_LOOK_ID
	INC I
	CMP I, 7
	JL %%CALC_SECOND_BLND_ROWS
	ADD v_delta_pos, CALC_SECOND_BLND_ROWS_INTRA_ANGLE
	LOAD_FROM_REF_MAIN XMMR0, CALC_SECOND_BLND_ROWS_START, CALC_SECOND_BLND_ROWS_EIGHT_SUB_LOOK_ID
	MOVDQA R8, XMMR0
	MB8 R1,  R2,  R3,  R4,  R5,  R6,  R7,  R8
	%undef		CALC_SECOND_BLND_ROWS_START
	%undef		CALC_SECOND_BLND_ROWS_INTRA_ANGLE
	%undef		CALC_SECOND_BLND_ROWS_EIGHT_SUB_LOOK_ID
%endmacro CALC_SECOND_BLND_ROWS

%macro CALC_FIRST_BLND_ROWS_MODE2 5
	PREPARE_DST_ADDRESS	%5
	MOV I, 0
%%CALC_FIRST_BLND_ROWS_MODE2
	PREDANG_CALCROW_HOR_MODE2 %1, %2, %4
	INC I
	CMP I, 8
	JL %%CALC_FIRST_BLND_ROWS_MODE2
	MB8 R1,  R2,  R3,  R4,  R5,  R6,  R7,  R8
%endmacro CALC_FIRST_BLND_ROWS

%macro CALC_SECOND_BLND_ROWS_MODE2 5
	PREPARE_DST_ADDRESS	%5
	MOV I, 0
%%CALC_SECOND_BLND_ROWS_MODE2
	PREDANG_CALCROW_HOR_MODE2 %1, %2, %4
	INC I
	CMP I, 7
	JL %%CALC_SECOND_BLND_ROWS_MODE2
	ADD v_delta_pos, %4
	MOVDQA XMMR0, %3
	MOVDQA R8, XMMR0
	MB8 R1,  R2,  R3,  R4,  R5,  R6,  R7,  R8
%endmacro CALC_FIRST_BLND_ROWS

%macro CALC_BLND_ROWS_MODE2_VER 5
%if %5 == 8
	MOV I, 0
%%CALC_BLND_ROWS_MODE2_VER_LABEL:
	PREDANG_CALCROW_VER_MODE2 %1, %2, %4
	INC I
	CMP I, 8
	JL %%CALC_BLND_ROWS_MODE2_VER_LABEL
%else
	MOV I, 0
%%CALC_BLND_ROWS_MODE2_VER_LABEL:
	PREDANG_CALCROW_VER_MODE2 %1, %2, %4
	INC I
	CMP I, 15
	JL %%CALC_BLND_ROWS_MODE2_VER_LABEL
	ADD v_delta_pos, %4
	MOVDQA XMMR0, %3
	STORE_VECTOR XMMR0
%endif
%endmacro CALC_FIRST_BLND_ROWS
%endif













%macro X265_INTRA_PRED_ANGLE_32_HELP_PIXEL_SSSE3 3
%if %2 > 1
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_I1:
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_J1:
	PXOR XMMR0, XMMR0
	LDDQU XMMR0, [ref_main]
	MOV temp_dst, dst
	MOV r0, %3
	IMUL r0, i_dst_stride_parameter
	SUB r0, %3
	MOV K, I
	ADD K, 1
%%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_K1:
	MOVDQA [temp_dst], XMMR0
	SUB_ADDRESS temp_dst, r0
	DEC K
	JNZ %%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_K1
	ADD_ADDRESS dst, i_dst_stride_parameter
    INC_ADDRESS ref_main
	INC J
	CMP J, %3
	JL %%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_J1
	INC I
	CMP I, %2 - 1
	JL %%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_I1
%endif
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_I2:
	MOV J, %2
%%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_J2:
	MOV r0, %2
	SUB r0, J
	IMUL r0, %3
%if 2 == SIZE_OF_PIXEL
	ADD r0, r0
%endif
	ADD r0, ref_main
	PXOR XMMR0, XMMR0
	LDDQU XMMR0, [r0]
	MOV r0, %2
	SUB r0, J
	IMUL r0, %3
	MOV temp_dst, dst
	ADD_ADDRESS  temp_dst, r0
	MOV r0, %3
	IMUL r0, i_dst_stride_parameter
	SUB r0, %3
	MOV K, 0
%%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_K2:
	MOVDQA [temp_dst], XMMR0
	SUB_ADDRESS temp_dst, r0
	INC K
	CMP K, J
	JL %%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_K2
	DEC J
	JNZ %%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_J2
	ADD_ADDRESS dst, i_dst_stride_parameter
	INC_ADDRESS ref_main
	INC I
	CMP I, %3
	JL %%X265_INTRA_PRED_ANGLE_32_PIXEL_SSSE3_I2
%endmacro

%macro X265_INTRA_PRED_ANGLE_H_HELP_PIXEL_SSSE3 4
%if 1 == SIZE_OF_PIXEL
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_H_HELP_PIXEL_SSSE3_I:
	MOV v_delta_pos, 0
	CALC_FIRST_BLND_ROWS 0, %2, %3
%if %4 > 16
	CALC_SECOND_BLND_ROWS 16, %2, %3
%endif
%if %4 > 32
	CALC_FIRST_BLND_ROWS 32, %2, %3
	CALC_SECOND_BLND_ROWS 48, %2, %3
%endif
	ADD J, 16
	CMP J, %4*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_H_HELP_PIXEL_SSSE3_I
%else
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_H_HELP_PIXEL_SSSE3_I:
	MOV v_delta_pos, 0
	CALC_FIRST_BLND_ROWS 0, %2, %3
%if %4 > 8
	CALC_FIRST_BLND_ROWS 8, %2, %3
%endif
%if %4 > 16
	CALC_FIRST_BLND_ROWS 16, %2, %3
	CALC_SECOND_BLND_ROWS 24, %2, %3
%endif
%if %4 > 32
	CALC_FIRST_BLND_ROWS 32, %2, %3
	CALC_FIRST_BLND_ROWS 40, %2, %3
	CALC_FIRST_BLND_ROWS 48, %2, %3
	CALC_SECOND_BLND_ROWS 56, %2, %3
%endif
	ADD J, 16
	CMP J, %4*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_H_HELP_PIXEL_SSSE3_I
%endif
%endmacro

%macro X265_INTRA_PRED_ANGLE_H_2_HELP_PIXEL_SSSE3 3
%if 1 == SIZE_OF_PIXEL
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_H_2_HELP_PIXEL_SSSE3_I:
	MOV v_delta_pos, 0
	LOAD_FROM_REF_MAIN ROW1, 0
	LOAD_FROM_REF_MAIN ROW2, 1
	CALC_BLND_ROWS_MODE2 ROW1, ROW2, ROW2, %3, 0
%if %2 > 16
	LOAD_FROM_REF_MAIN ROW1, 2
	CALC_BLND_ROWS_MODE2 ROW2, ROW1, ROW1, %3, 16
%endif
%if %2 > 32
	LOAD_FROM_REF_MAIN ROW2, 3
	CALC_BLND_ROWS_MODE2 ROW1, ROW2, ROW2, %3, 32
	LOAD_FROM_REF_MAIN ROW1, 4
	CALC_BLND_ROWS_MODE2 ROW2, ROW1, ROW1, %3, 48
%endif
	ADD J, 16
	CMP J, %2*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_H_2_HELP_PIXEL_SSSE3_I
%else
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_H_2_HELP_PIXEL_SSSE3_I:
	MOV v_delta_pos, 0
	LOAD_FROM_REF_MAIN ROW1, 0
	LOAD_FROM_REF_MAIN ROW2, 2
	CALC_FIRST_BLND_ROWS_MODE2 ROW1, ROW2, ROW2, %3, 0
%if %2 > 8
	CALC_SECOND_BLND_ROWS_MODE2 ROW1, ROW2, ROW2, %3, 8
%endif
%if %2 > 16
	LOAD_FROM_REF_MAIN ROW1, 4
	CALC_FIRST_BLND_ROWS_MODE2 ROW2, ROW1, ROW1, %3, 16
	CALC_SECOND_BLND_ROWS_MODE2 ROW2, ROW1, ROW1, %3, 24
%endif
%if %2 > 32
	LOAD_FROM_REF_MAIN ROW2, 6
	CALC_FIRST_BLND_ROWS_MODE2 ROW1, ROW2, ROW2, %3, 32
	CALC_SECOND_BLND_ROWS_MODE2 ROW1, ROW2, ROW2, %3, 40
	LOAD_FROM_REF_MAIN ROW1, 8
	CALC_FIRST_BLND_ROWS_MODE2 ROW2, ROW1, ROW1, %3, 48
	CALC_SECOND_BLND_ROWS_MODE2 ROW2, ROW1, ROW1, %3, 56
%endif
	ADD J, 16
	CMP J, %2*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_H_2_HELP_PIXEL_SSSE3_I
%endif
%endmacro

%macro X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3 3
%if 8 == %2
	MOV dst, dst_parameter
	MOV r0, r4m
	CMP r0, 0
	JNE %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_COPY_1
	PREPARE_PARAMETER
	MOVDQA XMMR2, [ref_side]
	CALC_FILTER_VALUE
	MOVDQA [dst], XMMR2
	ADD_ADDRESS dst, i_dst_stride_parameter
	JMP %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_COPY_15
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_COPY_1:
	MOV ref_main, ref_main_parameter
	MOVDQA XMMR0, [ref_main]
	PSHUFB XMMR0, [left_top_pshuffb_0_15]
	MOVDQA [dst], XMMR0
	ADD_ADDRESS dst, i_dst_stride_parameter
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_COPY_15:
	MOV ref_main, ref_main_parameter
	MOVDQA XMMR0, [ref_main]
	MOV J, 16
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_COPY_J:
	MOVDQA XMMR1, XMMR0
	PSHUFB XMMR1, [left_top_pshuffb_0_15+J]
	MOVDQA [dst], XMMR1
	ADD_ADDRESS dst, i_dst_stride_parameter
	ADD J, 16
	CMP J, 128
	JL %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_COPY_J
%elif 16 == %2
%if 1 == SIZE_OF_PIXEL
	MOV dst, dst_parameter
	MOV r0, r4m
	CMP r0, 0
	JNE %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_COPY_1
	PREPARE_PARAMETER
	MOVDQA XMMR2, XMMR4
	PUNPCKHBW XMMR2, XMMR6
	CALC_FILTER_VALUE
	MOVDQA XMMR1, XMMR2
	MOVDQA XMMR2, XMMR4
	PUNPCKLBW XMMR2, XMMR6
	CALC_FILTER_VALUE
	PACKUSWB XMMR2, XMMR1
	MOVDQA [dst], XMMR2
	ADD_ADDRESS dst, i_dst_stride_parameter
	JMP %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_COPY_15
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_COPY_1:
	MOV ref_main, ref_main_parameter
	MOVDQA XMMR0, [ref_main]
	PSHUFB XMMR0, [left_top_pshuffb_0_15]
	MOVDQA [dst], XMMR0
	ADD_ADDRESS dst, i_dst_stride_parameter
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_COPY_15:
	MOV ref_main, ref_main_parameter
	MOVDQA XMMR0, [ref_main]
	MOV J, 16
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_J:
	MOVDQA XMMR1, XMMR0
	PSHUFB XMMR1, [left_top_pshuffb_0_15+J]
	MOVDQA [dst], XMMR1
	ADD_ADDRESS dst, i_dst_stride_parameter
	ADD J, 16
	CMP J, 256
	JL %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_J
%else
	MOV dst, dst_parameter
	MOV r0, r4m
	CMP r0, 0
	JNE %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_COPY_1
	PREPARE_PARAMETER
	MOVDQA XMMR2, [ref_side]
	CALC_FILTER_VALUE
	MOVDQA [dst], XMMR2
	MOVDQA XMMR2, [ref_side+16]
	CALC_FILTER_VALUE
	MOVDQA [dst+16], XMMR2
	ADD_ADDRESS dst, i_dst_stride_parameter
	JMP %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_COPY_15
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_COPY_1:
	MOV ref_main, ref_main_parameter
	MOVDQA XMMR0, [ref_main]
	PSHUFB XMMR0, [left_top_pshuffb_0_15]
	MOVDQA [dst], XMMR0
	MOVDQA [dst+16], XMMR0
	ADD_ADDRESS dst, i_dst_stride_parameter
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_COPY_15:
	MOV ref_main, ref_main_parameter
	MOVDQA XMMR0, [ref_main]
	MOV J, 16
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_J1:
	MOVDQA XMMR1, XMMR0
	PSHUFB XMMR1, [left_top_pshuffb_0_15+J]
	MOV K, 0
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_K1:
	MOVDQA [dst+K], XMMR1
	ADD K, 16
	CMP K, 32
	JL %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_K1
	ADD_ADDRESS dst, i_dst_stride_parameter
	ADD J, 16
	CMP J, 128
	JL %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_J1
	MOVDQA XMMR0, [ref_main+16]
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_J2:
	MOVDQA XMMR1, XMMR0
	PSHUFB XMMR1, [left_top_pshuffb_0_15+J]
	MOV K, 0
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_K2:
	MOVDQA [dst+K], XMMR1
	ADD K, 16
	CMP K, 32
	JL %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_K2
	ADD_ADDRESS dst, i_dst_stride_parameter
	ADD J, 16
	CMP J, 128
	JL %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL_J2
%endif
%else
	MOV ref_main, %3
	MOV I, 0
	MOV dst, dst_parameter
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL1:
	MOVDQA XMMR0, [ref_main+I]
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABELJ:
	MOVDQA XMMR1, XMMR0
	PSHUFB XMMR1, [left_top_pshuffb_0_15+J]
	MOV K, 0
%%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABELK:
	MOVDQA [dst+K], XMMR1
	ADD K, 16
	CMP K, %2*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABELK
	ADD_ADDRESS dst, i_dst_stride_parameter
	ADD J, 16
%if 1 == SIZE_OF_PIXEL
	CMP J, 256
%else
	CMP J, 128
%endif
	JL %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABELJ
	ADD I, 16
	CMP I, %2*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_H_0_HELP_PIXEL_SSSE3_LABEL1
%endif
%endmacro


%macro X265_INTRA_PRED_ANGLE_H_M2_HELP_PIXEL_SSSE3 3
%if 1 == SIZE_OF_PIXEL
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_H_M2_HELP_PIXEL_SSSE3_I:
	MOV v_delta_pos, 0
	LOAD_FROM_REF_MAIN ROW1, -1
	LOAD_FROM_REF_MAIN ROW2,  0
	CALC_BLND_ROWS_MODE2 ROW1, ROW2, ROW1, %3, 0
%if %2 > 16
	LOAD_FROM_REF_MAIN ROW2, -2
	CALC_BLND_ROWS_MODE2 ROW2, ROW1, ROW2, %3, 16
%endif
%if %2 > 32
	LOAD_FROM_REF_MAIN ROW1, -3
	CALC_BLND_ROWS_MODE2 ROW1, ROW2, ROW1, %3, 32
	LOAD_FROM_REF_MAIN ROW2, -4
	CALC_BLND_ROWS_MODE2 ROW2, ROW1, ROW2, %3, 48
%endif
	ADD J, 16
	CMP J, %2*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_H_M2_HELP_PIXEL_SSSE3_I
%else
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_H_M2_HELP_PIXEL_SSSE3_I:
	MOV v_delta_pos, 0

	LOAD_FROM_REF_MAIN ROW1, -2
	LOAD_FROM_REF_MAIN ROW2,  0
	CALC_FIRST_BLND_ROWS_MODE2 ROW1, ROW2, ROW1, %3, 0
%if %2 > 8
	CALC_SECOND_BLND_ROWS_MODE2 ROW1, ROW2, ROW1, %3, 8
%endif
%if %2 > 16
	LOAD_FROM_REF_MAIN ROW2, -4
	CALC_FIRST_BLND_ROWS_MODE2 ROW2, ROW1, ROW2, %3, 16
	CALC_SECOND_BLND_ROWS_MODE2 ROW2, ROW1, ROW2, %3, 24
%endif
%if %2 > 32
	LOAD_FROM_REF_MAIN ROW1, -6
	CALC_FIRST_BLND_ROWS_MODE2 ROW1, ROW2, ROW1, %3, 32
	CALC_SECOND_BLND_ROWS_MODE2 ROW1, ROW2, ROW1, %3, 40
	LOAD_FROM_REF_MAIN ROW2, -8
	CALC_FIRST_BLND_ROWS_MODE2 ROW2, ROW1, ROW2, %3, 48
	CALC_SECOND_BLND_ROWS_MODE2 ROW2, ROW1, ROW2, %3, 56
%endif
	ADD J, 16
	CMP J, %2*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_H_M2_HELP_PIXEL_SSSE3_I
%endif
%endmacro


%macro X265_INTRA_PRED_ANGLE_V_HELP_PIXEL_SSSE3 4
	MOV v_delta_pos, 0
	MOV dst, dst_parameter
%if %4 == 8
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_V_HELP_PIXEL_SSSE3_LABEL:
	PREDANG_CALCROW_VER %2, %3, %4
	INC I
	CMP I, 8
	JL %%X265_INTRA_PRED_ANGLE_V_HELP_PIXEL_SSSE3_LABEL
%endif
%if %4 == 16
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_V_HELP_PIXEL_SSSE3_LABEL:
	PREDANG_CALCROW_VER %2, %3, %4
	INC I
	CMP I, 16
	JL %%X265_INTRA_PRED_ANGLE_V_HELP_PIXEL_SSSE3_LABEL
%endif
%if %4 == 32
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_V_HELP_PIXEL_SSSE3_LABEL:
	PREDANG_CALCROW_VER %2, %3, %4
	INC I
	CMP I, 31
	JL %%X265_INTRA_PRED_ANGLE_V_HELP_PIXEL_SSSE3_LABEL
	GET_REF_MAIN_ADDRESS_TO_R0 %3
	COPY_ONE_LINE %4
	ADD_ADDRESS dst, i_dst_stride_parameter
	ADD v_delta_pos, %2
	INC I
%endif
%if %4 == 64
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_V_HELP_PIXEL_SSSE3_LABEL1:
	PREDANG_CALCROW_VER %2, %3, %4
	INC I
	CMP I, 31
	JL %%X265_INTRA_PRED_ANGLE_V_HELP_PIXEL_SSSE3_LABEL1
	GET_REF_MAIN_ADDRESS_TO_R0 %3
	COPY_ONE_LINE %4
	ADD_ADDRESS dst, i_dst_stride_parameter
	ADD v_delta_pos, %2
	INC I
%%X265_INTRA_PRED_ANGLE_V_HELP_PIXEL_SSSE3_LABEL2:
	PREDANG_CALCROW_VER %2, %3, %4
	INC I
	CMP I, 63
	JL %%X265_INTRA_PRED_ANGLE_V_HELP_PIXEL_SSSE3_LABEL2
	GET_REF_MAIN_ADDRESS_TO_R0 %3
	COPY_ONE_LINE %4
	ADD_ADDRESS dst, i_dst_stride_parameter
	ADD v_delta_pos, %2
	INC I
%endif
%endmacro

%macro X265_INTRA_PRED_ANGLE_V_2_HELP_PIXEL_SSSE3 3
%if 1 == SIZE_OF_PIXEL
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_V_2_HELP_PIXEL_SSSE3_I:
	MOV v_delta_pos, 0
	MOV dst, dst_parameter
	ADD_ADDRESS dst, J
	LOAD_FROM_REF_MAIN ROW1, 0
	LOAD_FROM_REF_MAIN ROW2, 1
	CALC_BLND_ROWS_MODE2_VER ROW1, ROW2, ROW2, %3
%if %2 > 16
	LOAD_FROM_REF_MAIN ROW1, 2
	CALC_BLND_ROWS_MODE2_VER ROW2, ROW1, ROW1, %3
%endif
%if %2 > 32
	LOAD_FROM_REF_MAIN ROW2, 3
	CALC_BLND_ROWS_MODE2_VER ROW1, ROW2, ROW2, %3
	LOAD_FROM_REF_MAIN ROW1, 4
	CALC_BLND_ROWS_MODE2_VER ROW2, ROW1, ROW1, %3
%endif
	ADD J, 16
	CMP J, %2*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_V_2_HELP_PIXEL_SSSE3_I
%else

	MOV J, 0
%%X265_INTRA_PRED_ANGLE_V_2_HELP_PIXEL_SSSE3_I:
	MOV v_delta_pos, 0
	MOV dst, dst_parameter
	ADD dst, J
	LOAD_FROM_REF_MAIN ROW1, 0
	LOAD_FROM_REF_MAIN ROW2, 2
	CALC_BLND_ROWS_MODE2_VER ROW1, ROW2, ROW2, %3, %2
%if %2 > 16
	LOAD_FROM_REF_MAIN ROW1, 4
	CALC_BLND_ROWS_MODE2_VER ROW2, ROW1, ROW1, %3, %2
%endif
%if %2 > 32
	LOAD_FROM_REF_MAIN ROW2, 6
	CALC_BLND_ROWS_MODE2_VER ROW1, ROW2, ROW2, %3, %2
	LOAD_FROM_REF_MAIN ROW1, 8
	CALC_BLND_ROWS_MODE2_VER ROW2, ROW1, ROW1, %3, %2
%endif
	ADD J, 16
	CMP J, %2*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_V_2_HELP_PIXEL_SSSE3_I
%endif
%endmacro

%macro X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3 3
%if 8 == %2
	MOV ref_main, %3
	MOV dst, dst_parameter
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_LABEL_I:
	MOV dst, dst_parameter
	MOVDQA XMMR0, [ref_main+I]
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_LABEL_J:
	MOVDQA [dst], XMMR0
	ADD_ADDRESS dst, i_dst_stride_parameter
	INC J
	CMP J, 8
	JL %%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_LABEL_J
	ADD dst, 16
	ADD I, 16
	CMP I, 16
	JL %%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_LABEL_I
	MOV r0, r4m
	CMP r0, 0
	JNE %%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_LABEL_EXIT
	PREPARE_PARAMETER
	MOVDQA XMMR2, [ref_side]
	CALC_FILTER_VALUE
	STORE_V dst, i_dst_stride_parameter, XMMR2
%%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_LABEL_EXIT:
%elif 16 == %2
%if 1 == SIZE_OF_PIXEL
	MOV ref_main, ref_main_parameter
	MOV dst, dst_parameter
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_I:
	MOV dst, dst_parameter
	ADD dst, I
	MOVDQA XMMR0, [ref_main+I]
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_J:
	MOVDQA [dst], XMMR0
	ADD_ADDRESS dst, i_dst_stride_parameter
	INC J
	CMP J, 16
	JL %%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_J
	ADD dst, 16
	ADD I, 16
	CMP I, 16
	JL %%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_I
	MOV r0, r4m
	CMP r0, 0
	JNE %%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_EXIT
	PREPARE_PARAMETER
	MOVDQA XMMR2, XMMR4
	PUNPCKLBW XMMR2, XMMR6
	CALC_FILTER_VALUE
	PACKUSWB XMMR2, XMMR2
	STORE_V dst, i_dst_stride_parameter, XMMR2
	MOVDQA XMMR2, XMMR4
	PUNPCKHBW XMMR2, XMMR6
	CALC_FILTER_VALUE
	PACKUSWB XMMR2, XMMR2
	STORE_V dst, i_dst_stride_parameter, XMMR2
%%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_EXIT:
%else
	MOV ref_main, ref_main_parameter
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_I:
	MOV dst, dst_parameter
	ADD dst, I
	MOVDQA XMMR0, [ref_main+I]
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_J:
	MOVDQA [dst], XMMR0
	ADD_ADDRESS dst, i_dst_stride_parameter
	INC J
	CMP J, 16
	JL %%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_J
	ADD I, 16
	CMP I, 32
	JL %%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_I
	MOV r0, r4m
	CMP r0, 0
	JNE %%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_EXIT
	PREPARE_PARAMETER
	MOVDQA XMMR2, [ref_side]
	CALC_FILTER_VALUE
	STORE_V dst, i_dst_stride_parameter, XMMR2
	MOVDQA XMMR2, [ref_side+16]
	CALC_FILTER_VALUE
	STORE_V dst, i_dst_stride_parameter, XMMR2
%%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_EXIT:
%endif
%else
	MOV ref_main, %3
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_LABEL1:
	MOVDQA XMMR0, [ref_main+I]
	MOV dst, dst_parameter
	ADD dst, I
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_LABELJ:
	MOVDQA [dst], XMMR0
	ADD_ADDRESS dst, i_dst_stride_parameter
	INC J
	CMP J, %2
	JL %%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_LABELJ
	ADD dst, 16
	ADD I, 16
	CMP I, %2*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_V_0_HELP_PIXEL_SSSE3_LABEL1
	RET
%endif
%endmacro

%macro X265_INTRA_PRED_ANGLE_V_M2_HELP_PIXEL_SSSE3 3
%if 1 == SIZE_OF_PIXEL
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_V_M2_HELP_PIXEL_SSSE3_I:
	MOV v_delta_pos, 0
	MOV dst, dst_parameter
	ADD_ADDRESS dst, J
	LOAD_FROM_REF_MAIN ROW1, -1
	LOAD_FROM_REF_MAIN ROW2,  0
	CALC_BLND_ROWS_MODE2_VER ROW1, ROW2, ROW1, %3
%if %2 > 16
	LOAD_FROM_REF_MAIN ROW2, -2
	CALC_BLND_ROWS_MODE2_VER ROW2, ROW1, ROW2, %3
%endif
%if %2 > 32
	LOAD_FROM_REF_MAIN ROW1, -3
	CALC_BLND_ROWS_MODE2_VER ROW1, ROW2, ROW1, %3
	LOAD_FROM_REF_MAIN ROW2, -4
	CALC_BLND_ROWS_MODE2_VER ROW2, ROW1, ROW2, %3
%endif
	ADD J, 16
	CMP J, %2*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_V_M2_HELP_PIXEL_SSSE3_I
%else

	MOV J, 0
%%X265_INTRA_PRED_ANGLE_V_M2_HELP_PIXEL_SSSE3_I:
	MOV v_delta_pos, 0
	MOV dst, dst_parameter
	ADD dst, J
	LOAD_FROM_REF_MAIN ROW1, -2
	LOAD_FROM_REF_MAIN ROW2,  0
	CALC_BLND_ROWS_MODE2_VER ROW1, ROW2, ROW1, %3, %2
%if %2 > 16
	LOAD_FROM_REF_MAIN ROW2, -4
	CALC_BLND_ROWS_MODE2_VER ROW2, ROW1, ROW2, %3, %2
%endif
%if %2 > 32
	LOAD_FROM_REF_MAIN ROW1, -6
	CALC_BLND_ROWS_MODE2_VER ROW1, ROW2, ROW1, %3, %2
	LOAD_FROM_REF_MAIN ROW2, -8
	CALC_BLND_ROWS_MODE2_VER ROW2, ROW1, ROW2, %3, %2
%endif
	ADD J, 16
	CMP J, %2*SIZE_OF_PIXEL
	JL %%X265_INTRA_PRED_ANGLE_V_M2_HELP_PIXEL_SSSE3_I
%endif
%endmacro

%macro X265_INTRA_PRED_ANGLE_M32_HELP_PIXEL_SSSE3 5
	MOV ref_main, %4
	MOV dst, %5
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_I1:
	MOV J, %2
%%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_J1:
	MOV r0, %2
	SUB r0, J
	IMUL r0, %3
%if 2 == SIZE_OF_PIXEL
	ADD r0, r0
%endif	
	ADD r0, ref_main
	PXOR XMMR0, XMMR0
	LDDQU XMMR0, [r0]
	MOV r0, %2
	SUB r0, J
	IMUL r0, %3
	MOV temp_dst, dst
	ADD_ADDRESS  temp_dst, r0
	MOV r0, %3
	IMUL r0, i_dst_stride_parameter
	ADD r0, %3
	MOV K, 0
%%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_K1:
	MOVDQA [temp_dst], XMMR0
	ADD_ADDRESS temp_dst, r0
	INC K
	CMP K, J
	JL %%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_K1
	DEC J
	JNZ %%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_J1
	ADD_ADDRESS dst, i_dst_stride_parameter
	DEC_ADDRESS ref_main
	INC I
	CMP I, %3
	JL %%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_I1
%if %2 > 1
	MOV I, 0
%%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_I2:
	MOV J, 0
%%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_J2:
	PXOR XMMR0, XMMR0
	LDDQU XMMR0, [ref_main]
	MOV temp_dst, dst
	MOV r0, %3
	IMUL r0, i_dst_stride_parameter
	ADD r0, %3
	MOV K, %2 - 1
	SUB K, I
%%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_K2:
	MOVDQA [temp_dst], XMMR0
	ADD_ADDRESS temp_dst, r0
	DEC K
	JNZ %%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_K2
	ADD_ADDRESS dst, i_dst_stride_parameter
    DEC_ADDRESS ref_main
	INC J
	CMP J, %3
	JL %%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_J2
	INC I
	CMP I, %2 - 1
	JL %%X265_INTRA_PRED_ANGLE_M32_PIXEL_SSSE3_I2
%endif
%endmacro

